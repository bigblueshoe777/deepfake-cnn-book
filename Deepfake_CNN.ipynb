{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61f9664-c67a-477d-ab9b-1142996d18d7",
   "metadata": {},
   "source": [
    "# Deepfake Detection CNN — Executive Summary\n",
    "\n",
    "**TL;DR:** Lightweight, CPU-friendly CNN that detects deepfakes with strong baseline metrics and fully reproducible runs. Built to be clear, fast to iterate, and easy to review.\n",
    "\n",
    "- **Objective:** Build a deterministic baseline that runs on a laptop and produces defensible metrics.\n",
    "- **Data:** Public deepfake subset (Kaggle). Strict train/val/test split with class balance checks.\n",
    "- **Approach:** Compact CNN with careful preprocessing, regularization, and seeded experiments. Baselines for reference.\n",
    "- **Results (illustrative):** Accuracy ~92–95%, Precision/Recall >90%, AUC ~0.95. Calibrated threshold by cost.\n",
    "- **Why it matters:** Shows reliable signal without heavy infrastructure and uses production-minded habits that scale.\n",
    "\n",
    "## Sample data from dataset:\n",
    "\n",
    "![Sample Faces](outputs/SampleFaces.png \"Sample Faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a90a6-7146-4b84-9232-3f08c35de286",
   "metadata": {},
   "source": [
    "```{contents}\n",
    ":local:\n",
    ":depth: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c630ca7-7c7f-4444-9706-4bd3b769ddbc",
   "metadata": {},
   "source": [
    "## Results at a glance\n",
    "\n",
    "**Threshold:** logit ≥ 0.3018  *(≈ probability ≥ 0.575)*\n",
    "\n",
    "| Metric      | Value  |\n",
    "|-------------|:------:|\n",
    "| Accuracy    | 0.9222 |\n",
    "| Precision   | 0.9255 |\n",
    "| Recall      | 0.9182 |\n",
    "| F1-score    | 0.9218 |\n",
    "| ROC-AUC     | 0.9770 |\n",
    "\n",
    "---\n",
    "\n",
    "### Classification report\n",
    "\n",
    "| Class | Precision | Recall | F1-score | Support |\n",
    "|:-----:|:---------:|:------:|:--------:|-------:|\n",
    "| real  | 0.92 | 0.93 | 0.92 | 10000 |\n",
    "| fake  | 0.93 | 0.92 | 0.92 | 10000 |\n",
    "| **macro avg** | 0.92 | 0.92 | 0.92 | 20000 |\n",
    "| **weighted avg** | 0.92 | 0.92 | 0.92 | 20000 |\n",
    "\n",
    "**Overall accuracy:** 0.9222 (n = 20000)\n",
    "\n",
    "---\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "|               | **Pred: real** | **Pred: fake** |\n",
    "|---------------|:--------------:|:--------------:|\n",
    "| **Actual real** | 9261 | 739 |\n",
    "| **Actual fake** | 818  | 9182 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5e631-eb4e-417b-9186-9f1778350009",
   "metadata": {},
   "source": [
    "## Data Fetch, EDA, and Prep\n",
    "\n",
    "- **Source:** Kaggle deepfake subset with labeled real vs manipulated samples (https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces)\n",
    "- **Splits:** Train, validation, and test are strictly separated to avoid leakage\n",
    "- **Preprocessing:** Image resize, normalization\n",
    "- **Light Augmentation:** Deterministic and modest to reflect “production-friendly” training\n",
    "\n",
    "Taking a quick look, there are definitely some interesting features on some of these Fake faces that could tip off someone who is super vigilant, but at a glance they all seem close to the real thing. If tested with just my own brain I'd probably mislabel half of them.\n",
    "\n",
    "A quick note here: we're already aware that this dataset is perfectly balanced by design. On naturally-occuring data that hasn't been compiled nicely into \"real\" and \"fake\" folders we'd probably want to check the balance and fix it if necessary, but that won't be part of this notebook.\n",
    "\n",
    "Since I'm running this on my laptop CPU and in a Windows environment I imagine I might run into some issues handling this much of this kind of data. To try and keep things smooth while still generalizing the model more and preventing overfitting I'll normalize and then augment the images just a tad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d7d91-66c9-4cfb-bdab-5a2c05936a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the necessary libraries for this project\n",
    "import os, math, itertools, pathlib, json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    roc_curve, precision_recall_curve, balanced_accuracy_score)\n",
    "\n",
    "# define our tuneable paths and variables here\n",
    "data_path = 'C:/Users/bigbl/real_vs_fake/real-vs-fake'\n",
    "train_path = f'{data_path}/train'\n",
    "test_path = f'{data_path}/test'\n",
    "val_path = f'{data_path}/valid'\n",
    "\n",
    "IMG_SIZE = (220, 220)\n",
    "BATCH_SIZE = 22\n",
    "AUTOTUNE = tf.data.AUTOTUNE # for multithreading\n",
    "CLASSES = ['real', 'fake']\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# get some of that good stuff\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path, labels = 'inferred', label_mode = 'int', class_names = CLASSES,\n",
    "    image_size = IMG_SIZE, batch_size = BATCH_SIZE, shuffle = True, seed = SEED)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_path, labels = 'inferred', label_mode = 'int', class_names = CLASSES,\n",
    "    image_size = IMG_SIZE, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_path, labels = 'inferred', label_mode = 'int', class_names = CLASSES,\n",
    "    image_size = IMG_SIZE, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "class_names\n",
    "\n",
    "# check out the first batch for sanity's sake\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize = (12, 12))\n",
    "    for i in range(9):  # show 9 examples\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label = \"Real\" if labels[i].numpy() == 0 else \"Fake\"\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# make a cool function\n",
    "def configure(ds, training = False):\n",
    "    ds = ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, tf.cast(y, tf.float32)),\n",
    "                num_parallel_calls = AUTOTUNE) # first we should normalize pixel values\n",
    "    if training:\n",
    "        aug = keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),])\n",
    "            #layers.RandomBrightness(factor = 0.1),\n",
    "            #layers.RandomContrast(factor = 0.1),]) # wanted to use these but it ruined the model each time, go figure\n",
    "        ds = ds.map(lambda x, y: (aug(x, training = True), y), num_parallel_calls = AUTOTUNE)\n",
    "    return ds.prefetch(AUTOTUNE)\n",
    "\n",
    "# execute the cool function\n",
    "train_ds2 = configure(train_ds, training=True)\n",
    "val_ds2   = configure(val_ds, training=False)\n",
    "test_ds2  = configure(test_ds, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f96fa8-c5f7-47a6-8660-f5539005b5f9",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "A compact CNN designed to be clear and fast on CPU:\n",
    "- 3–4 convolutional blocks with batch normalization and dropout\n",
    "- Global average pooling and a small fully connected head\n",
    "- Cross-entropy loss with label smoothing for stability\n",
    "- Tracking metrics: accuracy, precision, recall, ROC-AUC\n",
    "\n",
    "Design choices favor determinism, auditability, and easy iteration over chasing maximum accuracy with heavy models. Keeping things lightweight for local resource management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6cbfe3-54ce-428f-b09b-eca70848ce47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DeepfakeCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DeepfakeCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,441</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,441\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,441</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m421,441\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def look_on_my_works_ye_mighty(input_shape = IMG_SIZE + (3,)):\n",
    "\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "\n",
    "    # convolution 1 - 32 3x3 filters, very basic edge detection\n",
    "    x = layers.Conv2D(32, 3, padding = 'same', activation = 'relu')(inputs) # ReLU adds nonlinear complexity\n",
    "    x = layers.MaxPooling2D()(x) # downsample the feature maps\n",
    "    \n",
    "    # convolution 2 - 64 3x3 filters to extract more abstract stuff (texture level)\n",
    "    x = layers.Conv2D(64, 3, padding = 'same', activation = 'relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    # convolution 3 - 128 3x3 filters for EVEN MORE DEPTH (facial features)\n",
    "    x = layers.Conv2D(128, 3, padding = 'same', activation = 'relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    # convolution 4 - 256 3x3 filters (whole faces)\n",
    "    x = layers.Conv2D(256, 3, padding = 'same', activation = 'relu')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # add learnable combination of the extracted features with some more nonlinearity\n",
    "    x = layers.Dense(128, activation = 'relu')(x)\n",
    "\n",
    "    # use logits here for sigmoid test later\n",
    "    logit = layers.Dense(1, activation = None)(x)\n",
    "\n",
    "    # smush it all together\n",
    "    model = keras.Model(inputs, logit, name = \"DeepfakeCNN\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# check it out and despair\n",
    "model = look_on_my_works_ye_mighty()\n",
    "model.summary()\n",
    "\n",
    "# use the logits here to monitor (threshold = 0.0 corresponds to about sigmoid(logit) >= 0.5 for training)\n",
    "threshy = 0.0\n",
    "METRICS = [\n",
    "    keras.metrics.BinaryAccuracy(name = 'accuracy', threshold = threshy),\n",
    "    keras.metrics.Precision(name = 'precision', thresholds = threshy),\n",
    "    keras.metrics.Recall(name = 'recall', thresholds = threshy),\n",
    "    keras.metrics.AUC(name = 'auc', from_logits = True),]\n",
    "\n",
    "# gotta compile the model\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 1e-3),\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    metrics = METRICS,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2361b27-a9c9-4830-b938-bc3ac7384821",
   "metadata": {},
   "source": [
    "## Training & Experiments\n",
    "\n",
    "- **Seeds:** Fixed across NumPy, framework, and loaders, the inevitable 42\n",
    "- **Schedule:** Early stopping on validation AUC and a simple learning-rate schedule\n",
    "- **Record-keeping:** Keep a compact experiment log with run id, params, and final metric\n",
    "\n",
    "It should be noted that settings previous to this point were tuned over several iterations and previous versions of this model were saved off but not polished for portfolio use.\n",
    "\n",
    "Things to consider:\n",
    "- Input resolution and crop strategy\n",
    "- Regularization strength (dropout, weight decay)\n",
    "- Threshold selection based on cost curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc4dbbd-5e43-4675-8687-75e4b1b705b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for use in our metric validator\n",
    "def collect_labels_and_scores(model, ds):\n",
    "    ys, zs = [], []\n",
    "    for x, y in ds:\n",
    "        ys.append(y.numpy().astype(int).ravel())\n",
    "        zs.append(model.predict(x, verbose = 0).ravel())\n",
    "    return np.concatenate(ys), np.concatenate(zs)\n",
    "\n",
    "# custom callback to be run every epoch\n",
    "class EvalOnVal(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        y_true, y_logit = collect_labels_and_scores(self.model, val_ds2)\n",
    "        y_pred = (y_logit >= 0.0).astype(int)\n",
    "        acc  = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division = 0)\n",
    "        rec  = recall_score(y_true, y_pred, zero_division = 0)\n",
    "        f1   = f1_score(y_true, y_pred, zero_division = 0)\n",
    "        auc  = roc_auc_score(y_true, y_logit) if len(np.unique(y_true)) == 2 else float('nan')\n",
    "        print(f\"\\n[VAL]  acc = {acc:.4f}  prec = {prec:.4f}  rec = {rec:.4f}  f1 = {f1:.4f}  auc = {auc:.4f}\")\n",
    "eval_cb = EvalOnVal()\n",
    "\n",
    "CALLBACKS = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss', patience = 5, restore_best_weights = True),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_loss', factor = 0.5, patience = 2, verbose = 1),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 'artifacts/best_cnn.keras', monitor = 'val_loss', save_best_only = True),\n",
    "    eval_cb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65ff8e-e28d-4eef-ae66-4a5220d2f0d7",
   "metadata": {},
   "source": [
    "<span style = \"color:red;font-size:20px\">THIS CODE BLOCK SET APART FROM OTHERS FOR EASY TESTING WORKFLOW</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96807551-90db-4384-b66a-8ef8619566e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.5537 - auc: 0.5767 - loss: 0.6818 - precision: 0.5542 - recall: 0.4916\n",
      "[VAL]  acc = 0.6520  prec = 0.6233  rec = 0.7682  f1 = 0.6882  auc = 0.7218\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1163s\u001b[0m 255ms/step - accuracy: 0.5895 - auc: 0.6293 - loss: 0.6662 - precision: 0.5964 - recall: 0.5534 - val_accuracy: 0.6520 - val_auc: 0.7218 - val_loss: 0.6228 - val_precision: 0.6233 - val_recall: 0.7682 - learning_rate: 0.0010\n",
      "Epoch 2/7\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6775 - auc: 0.7406 - loss: 0.5988 - precision: 0.6805 - recall: 0.6658\n",
      "[VAL]  acc = 0.7707  prec = 0.7920  rec = 0.7342  f1 = 0.7620  auc = 0.8507\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1153s\u001b[0m 254ms/step - accuracy: 0.7071 - auc: 0.7794 - loss: 0.5638 - precision: 0.7114 - recall: 0.6967 - val_accuracy: 0.7707 - val_auc: 0.8506 - val_loss: 0.4830 - val_precision: 0.7920 - val_recall: 0.7342 - learning_rate: 0.0010\n",
      "Epoch 3/7\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7898 - auc: 0.8709 - loss: 0.4491 - precision: 0.7977 - recall: 0.7751\n",
      "[VAL]  acc = 0.8320  prec = 0.8406  rec = 0.8195  f1 = 0.8299  auc = 0.9127\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1151s\u001b[0m 253ms/step - accuracy: 0.8066 - auc: 0.8888 - loss: 0.4198 - precision: 0.8156 - recall: 0.7924 - val_accuracy: 0.8321 - val_auc: 0.9127 - val_loss: 0.3746 - val_precision: 0.8406 - val_recall: 0.8195 - learning_rate: 0.0010\n",
      "Epoch 4/7\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.8469 - auc: 0.9249 - loss: 0.3478 - precision: 0.8562 - recall: 0.8329\n",
      "[VAL]  acc = 0.8662  prec = 0.8305  rec = 0.9203  f1 = 0.8731  auc = 0.9483\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1161s\u001b[0m 255ms/step - accuracy: 0.8561 - auc: 0.9328 - loss: 0.3301 - precision: 0.8655 - recall: 0.8433 - val_accuracy: 0.8662 - val_auc: 0.9483 - val_loss: 0.3124 - val_precision: 0.8305 - val_recall: 0.9203 - learning_rate: 0.0010\n",
      "Epoch 5/7\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8776 - auc: 0.9495 - loss: 0.2866 - precision: 0.8862 - recall: 0.8658\n",
      "[VAL]  acc = 0.8946  prec = 0.9093  rec = 0.8768  f1 = 0.8927  auc = 0.9610\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 254ms/step - accuracy: 0.8850 - auc: 0.9541 - loss: 0.2737 - precision: 0.8928 - recall: 0.8750 - val_accuracy: 0.8946 - val_auc: 0.9610 - val_loss: 0.2526 - val_precision: 0.9093 - val_recall: 0.8768 - learning_rate: 0.0010\n",
      "Epoch 6/7\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.8996 - auc: 0.9642 - loss: 0.2416 - precision: 0.9075 - recall: 0.8893\n",
      "[VAL]  acc = 0.9014  prec = 0.8746  rec = 0.9371  f1 = 0.9048  auc = 0.9689\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1158s\u001b[0m 255ms/step - accuracy: 0.9046 - auc: 0.9673 - loss: 0.2310 - precision: 0.9120 - recall: 0.8956 - val_accuracy: 0.9014 - val_auc: 0.9687 - val_loss: 0.2413 - val_precision: 0.8747 - val_recall: 0.9371 - learning_rate: 0.0010\n",
      "Epoch 7/7\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9146 - auc: 0.9732 - loss: 0.2085 - precision: 0.9206 - recall: 0.9071\n",
      "[VAL]  acc = 0.9169  prec = 0.9081  rec = 0.9277  f1 = 0.9178  auc = 0.9753\n",
      "\u001b[1m4546/4546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1162s\u001b[0m 256ms/step - accuracy: 0.9190 - auc: 0.9754 - loss: 0.1995 - precision: 0.9248 - recall: 0.9121 - val_accuracy: 0.9169 - val_auc: 0.9750 - val_loss: 0.2066 - val_precision: 0.9081 - val_recall: 0.9277 - learning_rate: 0.0010\n",
      "Best val AUC: 0.9750\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 7\n",
    "\n",
    "history = model.fit(train_ds2, validation_data = val_ds2, epochs = EPOCHS, callbacks = CALLBACKS)\n",
    "\n",
    "# quick glance code\n",
    "best_val_auc = max(history.history['val_auc'])\n",
    "print(f\"Best val AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4aa13-6ee6-4c19-992f-a27b51075c6a",
   "metadata": {},
   "source": [
    "\n",
    "## Results & Metrics\n",
    "\n",
    "Final test metrics and plots:\n",
    "\n",
    "- Learning curves to track progress and calibrate\n",
    "- Confusion matrix at the tuned threshold\n",
    "\n",
    "During testing I increased both `IMG_SIZE` and `BATCH_SIZE`, added a Batch Normalization to the model after every convolution (but before ReLU), and ran it to 5 epochs. It took nearly three times as long to process, and got **worse** results with a best F1-score of 0.87.\n",
    "\n",
    "**Takeaway:** Model is reliable on this dataset and in this configuration. Progress could likely come from better face alignment and smarter augmentations.\n",
    "\n",
    "# Error Analysis and Future Work\n",
    "\n",
    "- Inspect top false positives and false negatives and group by attributes:\n",
    "  - Lighting, occlusion, compression artifacts, manipulation type\n",
    "- Identify patterns where the model is brittle\n",
    "- Propose targeted data fixes or augmentations for those cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e2c58-7757-4a04-8dbb-9dc4e859a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    hist = history.history\n",
    "\n",
    "    plt.figure(); plt.plot(hist['loss'], label='train'); plt.plot(hist['val_loss'], label='val')\n",
    "    plt.title('Loss vs. Epochs'); plt.xlabel('Epoch'); plt.ylabel('BinaryCrossentropy'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    if 'accuracy' in hist and 'val_accuracy' in hist:\n",
    "        plt.figure(); plt.plot(hist['accuracy'], label='train'); plt.plot(hist['val_accuracy'], label='val')\n",
    "        plt.title('Accuracy vs. Epochs'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    if 'auc' in hist and 'val_auc' in hist:\n",
    "        plt.figure(); plt.plot(hist['auc'], label='train'); plt.plot(hist['val_auc'], label='val')\n",
    "        plt.title('ROC-AUC vs. Epochs'); plt.xlabel('Epoch'); plt.ylabel('AUC'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "# use this to collect spooky output logits\n",
    "def ghostbusters(model, ds):\n",
    "    ys, zs = [], []\n",
    "    for x, y in ds:\n",
    "        zs.append(model.predict(x, verbose = 0).ravel())\n",
    "        ys.append(y.numpy().astype(int).ravel())\n",
    "    return np.concatenate(ys), np.concatenate(zs)\n",
    "\n",
    "# pick F1-optimal threshold in *logit space*, on validation\n",
    "def f1_opt_logit_threshold(y_true, y_logit):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_logit)\n",
    "    f1 = 2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-9)\n",
    "    i  = int(np.nanargmax(f1)) # Nanargmax would be a great band name\n",
    "    return float(thr[i]), float(f1[i]), float(prec[i]), float(rec[i])\n",
    "\n",
    "y_true_val,  y_logit_val  = ghostbusters(model, val_ds2)\n",
    "y_true_test, y_logit_test = ghostbusters(model, test_ds2)\n",
    "\n",
    "thr_star, f1_val, p_val, r_val = f1_opt_logit_threshold(y_true_val, y_logit_val)\n",
    "print(f\"F1-optimized logit threshold: {thr_star:.4f} @ F1-score = {f1_val:.4f}\")\n",
    "\n",
    "# show me the money\n",
    "def summarize_at_logit_threshold(y_true, y_logit, thr_logit, label = 'Set'):\n",
    "    y_pred = (y_logit >= thr_logit).astype(int)\n",
    "    acc  = (y_true == y_pred).mean()\n",
    "    prec = precision_score(y_true, y_pred, zero_division = 0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division = 0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division = 0)\n",
    "    auc  = roc_auc_score(y_true, y_logit)\n",
    "    print(f\"\\n{label} @ logit ≥ {thr_logit:.4f}\")\n",
    "    print(f\"Accuracy : {acc:.4f}\\nPrecision: {prec:.4f}\\nRecall   : {rec:.4f}\\nF1-score : {f1:.4f}\\nROC-AUC  : {auc:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names = ['real','fake'], zero_division = 0))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    return {'acc':acc, 'prec':prec, 'rec':rec, 'f1':f1, 'auc':auc, 'cm':cm}\n",
    "\n",
    "val_summary  = summarize_at_logit_threshold(y_true_val,  y_logit_val,  thr_star, label = 'Validation')\n",
    "test_summary = summarize_at_logit_threshold(y_true_test, y_logit_test, thr_star, label = 'Test')\n",
    "\n",
    "def plot_confusion(cm, class_names=('real','fake'), title='Confusion Matrix'):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(class_names))\n",
    "    plt.xticks(ticks, class_names, rotation=45)\n",
    "    plt.yticks(ticks, class_names)\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i, j]), ha = \"center\", va = \"center\",\n",
    "                     color = \"black\" if cm[i, j] > thresh else \"white\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "y_pred_test = (y_logit_test >= thr_star).astype(int)\n",
    "cm_test = confusion_matrix(y_true_test, y_pred_test)\n",
    "plot_confusion(cm_test, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae043637-a8a2-4a66-9da0-1c35fc279715",
   "metadata": {},
   "source": [
    "## Figures\n",
    "\n",
    "![Loss (training curve)](outputs/Loss.png \"Loss curve\")\n",
    "\n",
    "![Accuracy (training curve)](outputs/Accuracy.png \"Accuracy curve\")\n",
    "\n",
    "![ROC-AUC (training curve)](outputs/CanYouSmellWhatTheROCIsCooking.png \"ROC-AUC curve\")\n",
    "\n",
    "![Confusion Matrix](outputs/confusion_matrix.png \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75a0aa-36dc-4e9b-83fc-b22c62ce47c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
